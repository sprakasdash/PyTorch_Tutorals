{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1 : PyTorch for Deep Neural Networks\n",
    "\n",
    "## Follow instructions given in the [PyTorch](http://pytorch.org/) website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A subtle introduction to PyTorch and its power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the library\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2]) tensor([[0.6503, 0.4969],\n",
      "        [0.0933, 0.0521]])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Defining tensors\n",
    "x = torch.tensor((2,2)) # Initialized with specific values\n",
    "y = torch.rand(2,2) # Random initialization\n",
    "print(x,y)\n",
    "\n",
    "# Obtaining size of tensors\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6503, 0.4969],\n",
      "        [0.0933, 0.0521]]) tensor([[0.9030, 0.5753],\n",
      "        [0.6100, 0.4583]]) tensor([[1.5533, 1.0722],\n",
      "        [0.7033, 0.5103]])\n",
      "tensor([[0.9030, 0.5753],\n",
      "        [0.6100, 0.4583]]) tensor([[1.8059, 1.1507],\n",
      "        [1.2200, 0.9165]])\n"
     ]
    }
   ],
   "source": [
    "# Arithmetic operations\n",
    "z = torch.rand(2,2)\n",
    "print(y,z,y+z)\n",
    "print(z,2*z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6503, 0.4969],\n",
      "        [0.0933, 0.0521]])\n",
      "tensor(0.0521)\n",
      "tensor([0.6503, 0.0933])\n"
     ]
    }
   ],
   "source": [
    "# Indexing is similar to numpy indexing\n",
    "print(y)\n",
    "print(y[1,1])\n",
    "print(y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Converting to numpy\n",
    "y_np = y.numpy()\n",
    "print(type(y))\n",
    "print(type(y_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]] tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Converting from numpy to tensor\n",
    "x_np = np.ones((3,3))\n",
    "x_py = torch.from_numpy(x_np)\n",
    "print(x_np,x_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU computation completed in 0.001812s, GPU computation completed in 0.000359s\n"
     ]
    }
   ],
   "source": [
    "# Improving computational time with GPU acceleration\n",
    "import time\n",
    "use_gpu = torch.cuda.is_available()\n",
    "x = torch.randn(1000,1000)\n",
    "if use_gpu:\n",
    "    cpuStart = time.time()\n",
    "    y = x*x\n",
    "    cpuEnd = time.time()-cpuStart\n",
    "    x = x.cuda()\n",
    "    gpuStart = time.time()\n",
    "    y = x*x\n",
    "    gpuEnd = time.time()-gpuStart\n",
    "    print('CPU computation completed in {:.6f}s, GPU computation completed in {:.6f}s'\\\n",
    "          .format(cpuEnd,gpuEnd))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd\n",
    " This package provides automatic differentiation for all operations on Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "a = torch.ones(2,2)\n",
    "a_var = Variable(a,requires_grad=True)\n",
    "print(a)\n",
    "print(a_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "b = a_var+2\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7f1eae65d198>\n"
     ]
    }
   ],
   "source": [
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "c = b*b*3\n",
    "d = c.mean()\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "# Gradients\n",
    "print(a_var.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torchvision datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torchvision import datasets,transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 9117696/9912422 [00:20<00:02, 301892.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
      "32768it [00:00, 43443.90it/s]            \u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1648877 [00:01<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 81920/1648877 [00:01<00:04, 340098.79it/s]\u001b[A\n",
      "  8%|▊         | 131072/1648877 [00:01<00:05, 283183.47it/s]\u001b[A\n",
      " 10%|█         | 172032/1648877 [00:01<00:06, 236199.62it/s]\u001b[A\n",
      " 13%|█▎        | 221184/1648877 [00:02<00:06, 215084.98it/s]\u001b[A\n",
      " 16%|█▋        | 270336/1648877 [00:02<00:06, 221935.08it/s]\u001b[A\n",
      " 19%|█▉        | 311296/1648877 [00:02<00:06, 203576.99it/s]\u001b[A\n",
      " 21%|██        | 344064/1648877 [00:02<00:07, 177733.62it/s]\u001b[A\n",
      " 23%|██▎       | 385024/1648877 [00:02<00:07, 175649.27it/s]\u001b[A\n",
      " 26%|██▌       | 425984/1648877 [00:03<00:07, 174354.87it/s]\u001b[A\n",
      " 29%|██▉       | 475136/1648877 [00:03<00:06, 182528.74it/s]\u001b[A\n",
      " 31%|███▏      | 516096/1648877 [00:03<00:05, 211772.51it/s]\u001b[A\n",
      " 33%|███▎      | 540672/1648877 [00:03<00:05, 208724.27it/s]\u001b[A\n",
      " 34%|███▍      | 565248/1648877 [00:03<00:05, 208537.10it/s]\u001b[A\n",
      " 36%|███▌      | 589824/1648877 [00:03<00:05, 206580.17it/s]\u001b[A\n",
      " 37%|███▋      | 614400/1648877 [00:04<00:04, 207392.18it/s]\u001b[A\n",
      " 39%|███▉      | 638976/1648877 [00:04<00:04, 205472.40it/s]\u001b[A\n",
      " 40%|████      | 663552/1648877 [00:04<00:04, 206715.54it/s]\u001b[A\n",
      " 42%|████▏     | 688128/1648877 [00:04<00:04, 205105.77it/s]\u001b[A\n",
      " 43%|████▎     | 712704/1648877 [00:04<00:04, 206354.35it/s]\u001b[A\n",
      " 45%|████▍     | 737280/1648877 [00:04<00:04, 204835.72it/s]\u001b[A\n",
      " 47%|████▋     | 770048/1648877 [00:04<00:03, 222544.11it/s]\u001b[A\n",
      " 48%|████▊     | 794624/1648877 [00:04<00:03, 215335.93it/s]\u001b[A\n",
      " 50%|████▉     | 819200/1648877 [00:04<00:03, 214002.83it/s]\u001b[A\n",
      " 51%|█████     | 843776/1648877 [00:05<00:03, 209334.48it/s]\u001b[A\n",
      " 53%|█████▎    | 868352/1648877 [00:05<00:03, 210061.00it/s]\u001b[A\n",
      " 54%|█████▍    | 892928/1648877 [00:05<00:03, 206605.52it/s]\u001b[A\n",
      " 56%|█████▌    | 925696/1648877 [00:05<00:03, 224642.24it/s]\u001b[A\n",
      " 58%|█████▊    | 950272/1648877 [00:05<00:03, 215755.40it/s]\u001b[A\n",
      " 59%|█████▉    | 974848/1648877 [00:05<00:03, 214979.27it/s]\u001b[A\n",
      " 61%|██████    | 999424/1648877 [00:05<00:03, 209369.02it/s]\u001b[A\n",
      " 63%|██████▎   | 1032192/1648877 [00:05<00:02, 227361.00it/s]\u001b[A\n",
      " 64%|██████▍   | 1056768/1648877 [00:06<00:02, 217283.78it/s]\u001b[A\n",
      " 66%|██████▌   | 1081344/1648877 [00:06<00:02, 215955.96it/s]\u001b[A\n",
      " 67%|██████▋   | 1105920/1648877 [00:06<00:02, 210313.49it/s]\u001b[A\n",
      " 69%|██████▊   | 1130496/1648877 [00:06<00:02, 211962.46it/s]\u001b[A\n",
      " 70%|███████   | 1155072/1648877 [00:06<00:02, 206047.42it/s]\u001b[A\n",
      " 72%|███████▏  | 1187840/1648877 [00:06<00:02, 225208.27it/s]\u001b[A\n",
      " 74%|███████▎  | 1212416/1648877 [00:06<00:02, 216276.22it/s]\u001b[A\n",
      " 75%|███████▌  | 1236992/1648877 [00:06<00:01, 216382.47it/s]\u001b[A\n",
      " 77%|███████▋  | 1261568/1648877 [00:07<00:01, 209412.42it/s]\u001b[A\n",
      " 78%|███████▊  | 1294336/1648877 [00:07<00:01, 227527.60it/s]\u001b[A\n",
      " 80%|███████▉  | 1318912/1648877 [00:07<00:01, 214350.82it/s]\u001b[A\n",
      "100%|█████████▉| 1646592/1648877 [00:08<00:00, 239380.50it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/4542 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "8192it [00:00, 16183.60it/s]            \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:39, 301892.40it/s]                             \n",
      "1654784it [00:27, 239380.50it/s]                             \u001b[A"
     ]
    }
   ],
   "source": [
    "apply_transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainDset = datasets.MNIST('./MNIST',train=True, download=True, transform= apply_transform)\n",
    "testDset = datasets.MNIST('./MNIST',train=False, download=True, transform= apply_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# Number of samples\n",
    "print(len(trainDset),len(testDset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying sample image from the dataset\n",
    "img = trainDset[0][0].numpy().transpose(1,2,0).squeeze(2)\n",
    "plt.imshow(img,'gray')\n",
    "print('Label: '+str(trainDset[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataloader for loading data in batches\n",
    "trainLoader = torch.utils.data.DataLoader(trainDset, batch_size=10, shuffle=True, num_workers=1, pin_memory=False)\n",
    "testLoader = torch.utils.data.DataLoader(testDset, batch_size=10, shuffle=True, num_workers=1, pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28,100)\n",
    "        self.fc2 = nn.Linear(100,10)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x,dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = MLP()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of first layer weights: torch.Size([100, 784])\n",
      "Dimensions of first layer bias: torch.Size([100])\n",
      "torch.Size([100, 784])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n",
      "Total number of parameters: 79510\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "# print('No. of parameters :'+str(len(params)))\n",
    "print('Dimensions of first layer weights: '+str(params[0].size())) # Weights of fc1\n",
    "print('Dimensions of first layer bias: '+str(params[1].size())) # Biases of fc1\n",
    "\n",
    "totalParams = 0\n",
    "for param in params:    \n",
    "    print(param.size())\n",
    "    totalParams += np.sum(np.prod(param.size()))\n",
    "print('Total number of parameters: '+str(totalParams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = trainLoader.dataset[0][0]\n",
    "label = trainLoader.dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "# Feed-forward data through network\n",
    "out = net(Variable(inp.view(-1,28*28)))\n",
    "print(inp.size())\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagating gradients\n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10)) # Using random gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6201, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "out = net(Variable(inp.view(-1,28*28)))\n",
    "# Defining loss function\n",
    "criterion = nn.NLLLoss() # Negative log-likelihood loss\n",
    "label = label*torch.ones(1).long() # Converting to tensor\n",
    "loss = criterion(out,Variable(label)) # NLLLoss() expects the labels to be of dtype 'long'\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias gradient of fc1 before backward\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Bias gradient of fc1 after backward\n",
      "tensor([ 0.0170,  0.0153, -0.0145,  0.0103, -0.0097, -0.0267,  0.0096,  0.0104,\n",
      "        -0.0178,  0.0031])\n"
     ]
    }
   ],
   "source": [
    "# Backprogation\n",
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('Bias gradient of fc1 before backward')\n",
    "print(net.fc1.bias.grad[:10])\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('Bias gradient of fc1 after backward')\n",
    "print(net.fc1.bias.grad[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0594, -0.0594, -0.0978,  0.0709,  0.0500])\n",
      "tensor([-0.1086, -0.1132, -0.1464,  0.0245,  0.0035])\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "# Updataing weights of the network\n",
    "learning_rate = 1\n",
    "init_params = copy.deepcopy(net.fc2.weight.data) # Copying initial parameters\n",
    "\n",
    "for f in net.parameters():    \n",
    "    f.data.sub_(f.grad.data * learning_rate)\n",
    "updated_params = net.fc2.weight.data\n",
    "print(init_params[0,:5])\n",
    "print(updated_params[0,:5])\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
